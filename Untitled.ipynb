{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ea2868-d96d-405d-8ed6-0983814a43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentiment_data import read_sentiment_examples\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from BOWmodels import SentimentDatasetBOW, NN2BOW, NN3BOW\n",
    "from DANmodels import DAN\n",
    "from sentiment_data import read_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aabea0-e8a6-4084-a509-cf4132be9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SentimentDatasetBOW(\"data/train.txt\")\n",
    "print(f\"First 5 examples: {train_data.examples[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132067b-deff-456b-bc62-996bfaeab7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sentences: {train_data.sentences[:5]}\")\n",
    "print(f\"Labels: {train_data.labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e32115-0d34-46e9-8392-6667768dbe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 14923 vectors of size 50\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WordEmbeddings' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m glove_embeddings \u001b[38;5;241m=\u001b[39m read_word_embeddings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/glove.6B.50d-relativized.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the DAN model with the loaded embeddings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dan_model \u001b[38;5;241m=\u001b[39m DAN(embeddings\u001b[38;5;241m=\u001b[39mglove_embeddings, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, fine_tune_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/cse256pa1/DANmodels.py:19\u001b[0m, in \u001b[0;36mDAN.__init__\u001b[0;34m(self, embeddings, hidden_size, dropout, num_layers, fine_tune_embeddings)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28msuper\u001b[39m(DAN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Initialize the embedding layer with pre-trained embeddings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m vocab_size, embedding_dim \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding\u001b[38;5;241m.\u001b[39mfrom_pretrained(embeddings, freeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m fine_tune_embeddings)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define layers for the feedforward neural network\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WordEmbeddings' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GloVe embeddings (for example, using 50-dimensional embeddings)\n",
    "glove_embeddings = read_word_embeddings(\"data/glove.6B.50d-relativized.txt\")\n",
    "\n",
    "# Initialize the DAN model with the loaded embeddings\n",
    "dan_model = DAN(embeddings=glove_embeddings, hidden_size=300, dropout=0.5, num_layers=2, fine_tune_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb6fea9-74b6-4cff-949f-ccfdffcf9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 14923 vectors of size 50\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = read_word_embeddings(\"data/glove.6B.50d-relativized.txt\")\n",
    "\n",
    "# Use the provided method to get a torch.nn.Embedding layer\n",
    "embedding_layer = glove_embeddings.get_initialized_embedding_layer(frozen=False)  # Set frozen=True to freeze embeddings\n",
    "\n",
    "# Initialize the DAN model using the embedding layer\n",
    "dan_model = DAN(embeddings=embedding_layer.weight, hidden_size=300, dropout=0.5, num_layers=2, fine_tune_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29e73d-91d8-429b-92c4-544a8f096fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dan_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c56a6ad-97f8-47b9-bd2e-ccca46ff4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000],\n",
      "         [ 0.2772,  0.8847, -0.2625,  0.0841,  0.4081, -1.1697, -0.6852,\n",
      "           0.1427, -0.5735, -0.5857, -0.5083, -0.8641, -0.5260, -0.5638,\n",
      "           0.3286,  0.4339, -0.2125,  0.4936, -1.8137, -0.0357,  1.3227,\n",
      "           0.8087,  0.0122, -0.0870, -0.1681, -1.5935,  0.4703,  0.2610,\n",
      "          -0.4167, -0.3853,  3.4413,  0.3438, -0.0359, -0.5678,  0.1838,\n",
      "          -0.4865,  0.4265,  0.4408,  1.0931,  0.0639, -0.0643, -0.2923,\n",
      "           0.0865,  0.3525,  0.1789,  0.2594,  0.3707, -0.5161,  0.0232,\n",
      "           0.0578],\n",
      "         [ 0.7672,  0.1239, -0.1112,  0.1336,  0.1836,  0.0579, -0.3341,\n",
      "          -0.6042,  0.4764,  0.2545,  0.1949, -0.0611, -0.4581, -0.1737,\n",
      "          -0.3272,  0.3347, -0.3218,  0.0905, -0.2468, -0.3547,  0.5527,\n",
      "          -0.3318, -0.5805, -0.5539, -0.6447, -1.8028, -0.6517,  0.4374,\n",
      "           0.0518,  0.2264,  4.2766,  0.1944, -0.1343, -0.1028, -0.0625,\n",
      "          -0.3907, -0.2938, -0.0135, -0.5814, -0.6972, -0.0689, -0.5005,\n",
      "          -0.0138, -0.1101, -0.6428,  0.4396, -0.2245,  0.4893, -0.2615,\n",
      "          -0.4689]]])\n",
      "Averaged sentence embedding: tensor([[ 3.4814e-01,  3.3620e-01, -1.2455e-01,  7.2551e-02,  1.9723e-01,\n",
      "         -3.7060e-01, -3.3977e-01, -1.5384e-01, -3.2360e-02, -1.1041e-01,\n",
      "         -1.0448e-01, -3.0842e-01, -3.2804e-01, -2.4584e-01,  4.8666e-04,\n",
      "          2.5622e-01, -1.7809e-01,  1.9472e-01, -6.8684e-01, -1.3014e-01,\n",
      "          6.2513e-01,  1.5896e-01, -1.8942e-01, -2.1364e-01, -2.7093e-01,\n",
      "         -1.1321e+00, -6.0463e-02,  2.3279e-01, -1.2162e-01, -5.2950e-02,\n",
      "          2.5726e+00,  1.7942e-01, -5.6725e-02, -2.2353e-01,  4.0435e-02,\n",
      "         -2.9240e-01,  4.4217e-02,  1.4242e-01,  1.7056e-01, -2.1109e-01,\n",
      "         -4.4392e-02, -2.6427e-01,  2.4233e-02,  8.0780e-02, -1.5464e-01,\n",
      "          2.3300e-01,  4.8713e-02, -8.9367e-03, -7.9452e-02, -1.3702e-01]])\n"
     ]
    }
   ],
   "source": [
    "# Now you can run the embedding test\n",
    "sentence_example = torch.tensor([[1, 23, 45]])  # A batch with a single sentence (adjust this to match your test case)\n",
    "embedded = dan_model.embedding(sentence_example)\n",
    "print(f\"Word embeddings: {embedded}\")\n",
    "avg_embedding = embedded.mean(dim=1)\n",
    "print(f\"Averaged sentence embedding: {avg_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85aeca5-768a-4e86-a638-0303c0d4b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "dan_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea6bd7-07bb-4b62-856b-baff9e914749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
